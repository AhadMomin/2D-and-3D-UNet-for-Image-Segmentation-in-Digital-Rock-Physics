{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D UNet for Image Segmentation in Digital Rock Petrophysics\n",
    "#### Ahad Momin (ahadmomin16@gmail.com)\n",
    "##### [GitHub](https://github.com/AhadMomin) | [Website](http://ahadmomin.github.io) |\n",
    "#### Supervisor: Christoph Arns & Masa Prodanovic\n",
    "#### Digital Rock Petrophysics\n",
    "\n",
    "### 3D UNet:\n",
    "#### The UNet Architecture is inspired by:  | [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://link.springer.com/chapter/10.1007/978-3-319-46723-8_49) |\n",
    "\n",
    "#### 3D UNet Model:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This deep neural network is implemented with Tensorflow and Keras functional API, which makes it extremely easy to experiment with different interesting architectures using GPU based enivronment\n",
    "\n",
    "\n",
    "#### Import Required Packages\n",
    "\n",
    "We will also need some standard packages. These should have been installed with Anaconda 3.\n",
    "\n",
    "#### Load the required libraries\n",
    "\n",
    "The following code loads the required libraries.\n",
    "\n",
    "Some of the workflow Style is inspired by: Prof Micheal Pyrcz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tifffile as tff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import notebook, tnrange\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import keras\n",
    "import imageio as imi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ahadm/Documents/UNSW Research/image segmentation CNN/UNET CNN/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images =  20\n"
     ]
    }
   ],
   "source": [
    "image_size = 64\n",
    "no_slices= 64\n",
    "epochs= 50\n",
    "path = \"train_data3D64/\"\n",
    "batch_size = 1\n",
    "ids = next(os.walk(path))[1]\n",
    "# print(ids)\n",
    "print(\"No. of images = \", len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(ids), no_slices, image_size, image_size, 3)).astype(np.float32)\n",
    "y = np.zeros((len(ids), no_slices, image_size, image_size, 1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07c84255ebd4838803e4420939cc92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "(64, 64, 64, 1) uint8 (20, 64, 64, 64, 3) float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, id_ in notebook.tqdm(enumerate(ids), total=len(ids)):\n",
    "    image_sequence = tff.imread(path+id_+\"/images/\"+id_+\".tif\")  \n",
    "    image_sequence = np.expand_dims(image_sequence,axis=3)\n",
    "    \n",
    "    segmented= tff.imread(path+id_+\"/segmented/\"+id_+\".tif\")\n",
    "    segmented = np.expand_dims(segmented,axis=3)\n",
    "    \n",
    "    X[n] = (image_sequence/255.0)\n",
    "    y[n] = (segmented/255.0)\n",
    "    print(image_sequence.shape,image_sequence.dtype, X.shape,X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 64, 64, 64, 3) float32 (20, 64, 64, 64, 1) float32 (64, 64, 64, 1) float32 (64, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,X.dtype,y.shape,y.dtype,image_sequence.shape,y.dtype,segmented.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomogram dimension in Training =  (18, 64, 64, 64, 3) float32\n",
      "Segmented dimension in Training  =  (18, 64, 64, 64, 1) float32\n",
      "Tomogram dimension in Testing =  (2, 64, 64, 64, 3) float32\n",
      "Segmented dimension in Testing =  (2, 64, 64, 64, 1) float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Tomogram dimension in Training = \", X_train.shape,(X_train*255).dtype)\n",
    "print(\"Segmented dimension in Training  = \",y_train.shape, y_train.dtype)\n",
    "print(\"Tomogram dimension in Testing = \",X_test.shape,X_test.dtype)\n",
    "print(\"Segmented dimension in Testing = \",y_test.shape,y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_Norm_Activation(x, BN=True):\n",
    "    if BN == True:\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "    else:\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "def Unet3D(featuremaps):\n",
    "    inputs = keras.engine.Input((no_slices, image_size, image_size, 3))\n",
    "    #encoder\n",
    "    conv1 = keras.layers.Conv3D(featuremaps*1, (3,3,3),activation= None, padding = \"same\")(inputs)\n",
    "    conv1 = batch_Norm_Activation(conv1)\n",
    "    conv1 = keras.layers.Conv3D(featuremaps*1, (3,3,3),activation= None, padding = \"same\")(conv1)\n",
    "    conv1 = batch_Norm_Activation(conv1)\n",
    "    pool1  = keras.layers.MaxPooling3D((2,2,2))(conv1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv3D(featuremaps * 2, (3, 3 ,3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = batch_Norm_Activation(conv2)\n",
    "    conv2 = keras.layers.Conv3D(featuremaps * 2, (3, 3, 3), activation=None, padding=\"same\")(conv2)\n",
    "    conv2 = batch_Norm_Activation(conv2)\n",
    "    pool2 = keras.layers.MaxPooling3D((2, 2, 2))(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv3D(featuremaps * 4, (3, 3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = batch_Norm_Activation(conv3)\n",
    "    conv3 = keras.layers.Conv3D(featuremaps * 4, (3, 3, 3), activation=None, padding=\"same\")(conv3)\n",
    "    conv3 = batch_Norm_Activation(conv3)\n",
    "    pool3 = keras.layers.MaxPooling3D((2, 2, 2))(conv3)\n",
    "    \n",
    "    conv4 = keras.layers.Conv3D(featuremaps * 8, (3, 3, 3), activation=None, padding =\"same\")(pool3)\n",
    "    conv4 = batch_Norm_Activation(conv4)\n",
    "    conv4 = keras.layers.Conv3D(featuremaps * 8, (3, 3, 3), activation=None, padding =\"same\")(conv4)\n",
    "    conv4 = batch_Norm_Activation(conv4)\n",
    "    pool4 = keras.layers.MaxPooling3D((2, 2, 2))(conv4)\n",
    "\n",
    "    # bridge\n",
    "    convm = keras.layers.Conv3D(featuremaps * 16, (3, 3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = batch_Norm_Activation(convm)\n",
    "    convm = keras.layers.Conv3D(featuremaps * 16, (3, 3, 3), activation=None, padding=\"same\")(convm)\n",
    "    convm = batch_Norm_Activation(convm)\n",
    "    \n",
    "    #decoder\n",
    "    deconv4 = keras.layers.Conv3DTranspose(featuremaps* 8, (2, 2, 2), strides=(2,2,2), padding =\"same\")(convm)\n",
    "    uconv4 = keras.layers.concatenate([deconv4, conv4])\n",
    "    uconv4 = keras.layers.Conv3D(featuremaps* 8, (2 , 2, 2), activation = None, padding= \"same\")(uconv4)\n",
    "    uconv4 = batch_Norm_Activation(uconv4)\n",
    "    uconv4 = keras.layers.Conv3D(featuremaps* 8, (2 , 2, 2), activation = None, padding= \"same\")(uconv4)\n",
    "    uconv4 = batch_Norm_Activation(uconv4)\n",
    "\n",
    "    \n",
    "    deconv3 = keras.layers.Conv3DTranspose(featuremaps * 4, (2, 2, 2), strides=(2, 2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = keras.layers.concatenate([deconv3, conv3])\n",
    "    uconv3 = keras.layers.Conv3D(featuremaps * 4, (2, 2, 2), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = batch_Norm_Activation(uconv3)\n",
    "    uconv3 = keras.layers.Conv3D(featuremaps * 4, (2, 2, 2), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = batch_Norm_Activation(uconv3)\n",
    "\n",
    "    \n",
    "    deconv2 = keras.layers.Conv3DTranspose(featuremaps* 2, (2, 2, 2), strides = (2, 2, 2), padding= \"same\")(uconv3)\n",
    "    uconv2 = keras.layers.concatenate([deconv2, conv2])\n",
    "    uconv2 = keras.layers.Conv3DTranspose(featuremaps* 2, (2, 2, 2), activation = None, padding = \"same\")(uconv2)\n",
    "    uconv2 = batch_Norm_Activation(uconv2)\n",
    "    uconv2 = keras.layers.Conv3DTranspose(featuremaps* 2, (2, 2, 2), activation = None, padding = \"same\")(uconv2)\n",
    "    uconv2 = batch_Norm_Activation(uconv2)\n",
    "\n",
    "\n",
    "    deconv1 = keras.layers.Conv3DTranspose(featuremaps * 1, (2, 2 ,2), strides=(2, 2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = keras.layers.concatenate([deconv1, conv1])\n",
    "    uconv1 = keras.layers.Conv3D(featuremaps * 1, (2, 2, 2), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = batch_Norm_Activation(uconv1)\n",
    "    uconv1 = keras.layers.Conv3D(featuremaps * 1, (2, 2,2), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = batch_Norm_Activation(uconv1)\n",
    "\n",
    "    \n",
    "    output_layer = keras.layers.Conv3D(1, (1, 1 ,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    model = keras.models.Model(inputs, output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_1:0' shape=(None, 64, 64, 64, 3) dtype=float32>]\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 64, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 64, 64, 64, 6 5248        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 64, 6 256         conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64, 6 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 64, 64, 64, 6 110656      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64, 6 256         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 32, 32, 32, 6 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 32, 32, 32, 1 221312      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32, 1 512         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32, 1 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 32, 32, 32, 1 442496      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 32, 1 512         conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 32, 1 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 16, 16, 16, 1 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 16, 16, 16, 2 884992      max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 16, 2 1024        conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 16, 2 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 16, 16, 16, 2 1769728     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 16, 2 1024        conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 16, 2 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 8, 8, 8, 256) 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 8, 8, 8, 512) 3539456     max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 8, 512) 2048        conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 8, 512) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 8, 8, 8, 512) 7078400     activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 8, 512) 2048        conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 8, 512) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 4, 4, 4, 512) 0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 4, 4, 4, 1024 14156800    max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 4, 1024 4096        conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4, 4, 4, 1024 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 4, 4, 4, 1024 28312576    activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 4, 1024 4096        conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 4, 1024 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTrans (None, 8, 8, 8, 512) 4194816     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 8, 1024 0           conv3d_transpose_1[0][0]         \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 8, 8, 8, 512) 4194816     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 8, 512) 2048        conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 8, 512) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 8, 8, 8, 512) 2097664     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 8, 512) 2048        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 8, 512) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTrans (None, 16, 16, 16, 2 1048832     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 16, 5 0           conv3d_transpose_2[0][0]         \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 16, 16, 16, 2 1048832     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 16, 2 1024        conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 16, 2 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 16, 16, 16, 2 524544      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 16, 2 1024        conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 16, 2 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTrans (None, 32, 32, 32, 1 262272      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 32, 2 0           conv3d_transpose_3[0][0]         \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_4 (Conv3DTrans (None, 32, 32, 32, 1 262272      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 32, 1 512         conv3d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 32, 1 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_5 (Conv3DTrans (None, 32, 32, 32, 1 131200      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 32, 1 512         conv3d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 32, 1 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_6 (Conv3DTrans (None, 64, 64, 64, 6 65600       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 64, 1 0           conv3d_transpose_6[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 64, 64, 64, 6 65600       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 64, 6 256         conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 64, 6 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 64, 64, 64, 6 32832       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 64, 6 256         conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 64, 6 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 64, 64, 64, 1 65          activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 70,474,561\n",
      "Trainable params: 70,462,785\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Unet3D(64)\n",
    "print(model.inputs)\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
    "model.compile(optimizer=sgd, loss=\"mean_squared_error\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint('model-3dtest1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples, validate on 2 samples\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.1059 - acc: 0.6908 - val_loss: 0.1284 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12839, saving model to model-3dtest1.h5\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0191 - acc: 0.8065 - val_loss: 0.0793 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12839 to 0.07932, saving model to model-3dtest1.h5\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0114 - acc: 0.8073 - val_loss: 0.0567 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07932 to 0.05671, saving model to model-3dtest1.h5\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.0092 - acc: 0.8074 - val_loss: 0.0454 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05671 to 0.04538, saving model to model-3dtest1.h5\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0081 - acc: 0.8074 - val_loss: 0.0401 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04538 to 0.04008, saving model to model-3dtest1.h5\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0074 - acc: 0.8074 - val_loss: 0.0370 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04008 to 0.03698, saving model to model-3dtest1.h5\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0069 - acc: 0.8074 - val_loss: 0.0357 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03698 to 0.03574, saving model to model-3dtest1.h5\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0066 - acc: 0.8074 - val_loss: 0.0353 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03574 to 0.03529, saving model to model-3dtest1.h5\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0062 - acc: 0.8074 - val_loss: 0.0350 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03529 to 0.03495, saving model to model-3dtest1.h5\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.0059 - acc: 0.8074 - val_loss: 0.0346 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03495 to 0.03459, saving model to model-3dtest1.h5\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.0057 - acc: 0.8074 - val_loss: 0.0341 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03459 to 0.03411, saving model to model-3dtest1.h5\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.0055 - acc: 0.8074 - val_loss: 0.0333 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03411 to 0.03328, saving model to model-3dtest1.h5\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.0053 - acc: 0.8074 - val_loss: 0.0318 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03328 to 0.03180, saving model to model-3dtest1.h5\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.0052 - acc: 0.8074 - val_loss: 0.0309 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03180 to 0.03092, saving model to model-3dtest1.h5\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0051 - acc: 0.8074 - val_loss: 0.0292 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03092 to 0.02922, saving model to model-3dtest1.h5\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.0049 - acc: 0.8074 - val_loss: 0.0277 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02922 to 0.02772, saving model to model-3dtest1.h5\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.0048 - acc: 0.8074 - val_loss: 0.0254 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02772 to 0.02543, saving model to model-3dtest1.h5\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0047 - acc: 0.8074 - val_loss: 0.0231 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02543 to 0.02307, saving model to model-3dtest1.h5\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0046 - acc: 0.8074 - val_loss: 0.0214 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02307 to 0.02144, saving model to model-3dtest1.h5\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0046 - acc: 0.8074 - val_loss: 0.0175 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02144 to 0.01748, saving model to model-3dtest1.h5\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0044 - acc: 0.8074 - val_loss: 0.0165 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01748 to 0.01654, saving model to model-3dtest1.h5\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0044 - acc: 0.8074 - val_loss: 0.0148 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01654 to 0.01476, saving model to model-3dtest1.h5\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0043 - acc: 0.8074 - val_loss: 0.0133 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01476 to 0.01325, saving model to model-3dtest1.h5\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0043 - acc: 0.8074 - val_loss: 0.0120 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01325 to 0.01198, saving model to model-3dtest1.h5\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0042 - acc: 0.8074 - val_loss: 0.0101 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01198 to 0.01006, saving model to model-3dtest1.h5\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0042 - acc: 0.8074 - val_loss: 0.0084 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01006 to 0.00839, saving model to model-3dtest1.h5\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0041 - acc: 0.8074 - val_loss: 0.0085 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00839\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0041 - acc: 0.8074 - val_loss: 0.0070 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00839 to 0.00697, saving model to model-3dtest1.h5\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0041 - acc: 0.8074 - val_loss: 0.0061 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00697 to 0.00606, saving model to model-3dtest1.h5\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0040 - acc: 0.8074 - val_loss: 0.0055 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00606 to 0.00548, saving model to model-3dtest1.h5\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0039 - acc: 0.8074 - val_loss: 0.0050 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00548 to 0.00501, saving model to model-3dtest1.h5\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0039 - acc: 0.8074 - val_loss: 0.0046 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00501 to 0.00457, saving model to model-3dtest1.h5\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0039 - acc: 0.8074 - val_loss: 0.0043 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00457 to 0.00434, saving model to model-3dtest1.h5\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0038 - acc: 0.8074 - val_loss: 0.0040 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00434 to 0.00399, saving model to model-3dtest1.h5\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0038 - acc: 0.8074 - val_loss: 0.0038 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00399 to 0.00379, saving model to model-3dtest1.h5\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0038 - acc: 0.8074 - val_loss: 0.0039 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00379\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0038 - acc: 0.8074 - val_loss: 0.0038 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00379\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0037 - acc: 0.8074 - val_loss: 0.0033 - val_acc: 0.8293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss improved from 0.00379 to 0.00333, saving model to model-3dtest1.h5\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0037 - acc: 0.8074 - val_loss: 0.0034 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00333\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0037 - acc: 0.8074 - val_loss: 0.0032 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00333 to 0.00319, saving model to model-3dtest1.h5\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0037 - acc: 0.8074 - val_loss: 0.0034 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00319\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0036 - acc: 0.8074 - val_loss: 0.0031 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00319 to 0.00310, saving model to model-3dtest1.h5\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0037 - acc: 0.8074 - val_loss: 0.0030 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00310 to 0.00303, saving model to model-3dtest1.h5\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0036 - acc: 0.8074 - val_loss: 0.0032 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00303\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0036 - acc: 0.8074 - val_loss: 0.0032 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00303\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0035 - acc: 0.8074 - val_loss: 0.0032 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00303\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0036 - acc: 0.8074 - val_loss: 0.0031 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00303\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0035 - acc: 0.8074 - val_loss: 0.0029 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00303 to 0.00294, saving model to model-3dtest1.h5\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0034 - acc: 0.8074 - val_loss: 0.0028 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00294 to 0.00279, saving model to model-3dtest1.h5\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0035 - acc: 0.8074 - val_loss: 0.0028 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00279 to 0.00277, saving model to model-3dtest1.h5\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,callbacks=callbacks,\\\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(hist.history[\"val_loss\"]), np.min(hist.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2/2 [==============================] - 4s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0027675125747919083, 0.8292827606201172]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model-3dtest1.h5')\n",
    "model.evaluate(X_test, y_test, verbose=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 314ms/step\n",
      "2/2 [==============================] - 1s 282ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_test = model.predict(X_test, verbose=1)\n",
    "preds_train= model.predict(X_train[0:2], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 64, 64, 64, 3) (20, 64, 64, 64, 3)\n",
      "(2, 64, 64, 64, 3)\n",
      "(2, 64, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X.shape)\n",
    "print(X_test.shape)\n",
    "print(preds_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(X, y, preds, r=None):\n",
    "    if r is None:\n",
    "        r = random.randint(0, len(X))\n",
    "        print(r)\n",
    "        \n",
    "    X1= X[r,...,0].squeeze()\n",
    "    tff.imwrite('tomogram1.tif', X1 , imagej=True)\n",
    "    print(X1.shape,X1.dtype)\n",
    "        \n",
    "    y1 = y[r].squeeze()\n",
    "    tff.imwrite('GR1.tif', y1 , imagej=False)\n",
    "    print(y1.shape,y1.dtype)\n",
    "\n",
    "    preds1=preds[r].squeeze()\n",
    "    tff.imwrite('predicted1.tif',preds1, imagej=True)\n",
    "    print(preds1.shape,preds1.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64) float32\n",
      "(64, 64, 64) float32\n",
      "(64, 64, 64) float32\n"
     ]
    }
   ],
   "source": [
    "save_sample(X_test,y_test,preds_test,r=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sample(X_train,y_train,preds_train, r=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorgpu",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
